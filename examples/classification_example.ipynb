{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuristic Example: Text Classification\n",
    "\n",
    "This notebook demonstrates how to use Featuristic to classify text documents based on their content.\n",
    "\n",
    "It utilizes a dataset of news articles which fall into one of the following categories:\n",
    "- Related to the war between Russia and Ukraine\n",
    "- Related to the diplomatic relations between the US and UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add featuristic library to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(\"./../\"))\n",
    "\n",
    "from featuristic import FeaturisticClassifier\n",
    "from featuristic import PromptFeatureDefinition, PromptFeatureConfiguration, extract_features\n",
    "from featuristic import Distribution\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API variables\n",
    "\n",
    "Configure your API key, base URL, version, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual API key and endpoint\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "API_BASE = os.getenv(\"API_BASE\")\n",
    "API_VERSION = os.getenv(\"API_VERSION\")\n",
    "MODEL = os.getenv(\"MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "Load data from JSON files and prepare training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    return [json.loads(d)[\"text\"].strip().replace(\"\\n\\n\", \"\\n\") for d in data if \"text\" in json.loads(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "russia_ukraine = load_data(\"data/russia_ukraine_2025.jsonl\")\n",
    "ones = np.ones(len(russia_ukraine))\n",
    "\n",
    "uk_us_relationship = load_data(\"data/uk_us_relationship.jsonl\")\n",
    "zeros = np.zeros(len(uk_us_relationship))\n",
    "\n",
    "X = russia_ukraine + uk_us_relationship\n",
    "y = np.concatenate([ones, zeros])\n",
    "\n",
    "# Split into training and testing datasets\n",
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# For demonstration purposes, use small samples\n",
    "data_train = data_train[:10]\n",
    "y_train = y_train[:10]\n",
    "\n",
    "data_test = data_test[:10]\n",
    "y_test = y_test[:10]\n",
    "\n",
    "print(f\"Training samples: {len(data_train)}\")\n",
    "print(f\"Testing samples: {len(data_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get a random example from each class\n",
    "random_russia_ukraine = random.choice(russia_ukraine)\n",
    "random_uk_us_relationship = random.choice(uk_us_relationship)\n",
    "\n",
    "print(\"==== Example from Russia-Ukraine class ====\")\n",
    "print(random_russia_ukraine)\n",
    "print(\"\\n\\n==== Example from UK-US relationship class ===\")\n",
    "print(random_uk_us_relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Definition\n",
    "\n",
    "Define LLM-based features we'll use for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature configuration\n",
    "config = PromptFeatureConfiguration(\n",
    "    api_base=API_BASE,\n",
    "    api_version=API_VERSION,\n",
    "    api_key=API_KEY,\n",
    "    model=MODEL,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "# Helper function for text proportion features\n",
    "def as_propotion_of_text(x, text):\n",
    "    return x/len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for classification\n",
    "mention_of_war = PromptFeatureDefinition(\n",
    "    name=\"mention_of_war\",\n",
    "    prompt=\"Whether or not the notion of war is mentioned\",\n",
    "    llm_return_type=bool,\n",
    "    distribution=Distribution.BERNOULLI,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "mention_of_casualties = PromptFeatureDefinition(\n",
    "    name=\"mention_of_casualties\",\n",
    "    prompt=\"Whether or not the notion of casualities are mentioned\",\n",
    "    llm_return_type=bool,\n",
    "    distribution=Distribution.BERNOULLI,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "mentions_weapons = PromptFeatureDefinition(\n",
    "    name=\"mentions_weapons\",\n",
    "    prompt=\"Whether or not the notion of weapons are mentioned\",\n",
    "    llm_return_type=bool,\n",
    "    distribution=Distribution.BERNOULLI,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "mentions_US = PromptFeatureDefinition(\n",
    "    name=\"mentions_US\",\n",
    "    prompt=\"A count of references to the United States\",\n",
    "    llm_return_type=int,\n",
    "    feature_post_callback=as_propotion_of_text,\n",
    "    distribution=Distribution.GAUSSIAN,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "mentions_Russia = PromptFeatureDefinition(\n",
    "    name=\"mentions_Russia\",\n",
    "    prompt=\"A count of references to Russians, Russia, or a place in Russia\",\n",
    "    llm_return_type=int,\n",
    "    feature_post_callback=as_propotion_of_text,\n",
    "    distribution=Distribution.GAUSSIAN,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "mentions_Ukraine = PromptFeatureDefinition(\n",
    "    name=\"mentions_Ukraine\",\n",
    "    prompt=\"A count of references to Ukrainians, Ukraine, or any place in Ukraine\",\n",
    "    llm_return_type=int,\n",
    "    feature_post_callback=as_propotion_of_text,\n",
    "    distribution=Distribution.GAUSSIAN,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "mentions_Putin = PromptFeatureDefinition(\n",
    "    name=\"mentions_Putin\",\n",
    "    prompt=\"A count of the references to Vladamir Putin\",\n",
    "    llm_return_type=int,\n",
    "    feature_post_callback=as_propotion_of_text,\n",
    "    distribution=Distribution.GAUSSIAN,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "russian_ukraine_theme = PromptFeatureDefinition(\n",
    "    name=\"russian_ukraine_theme\",\n",
    "    prompt=\"Whether or not the theme of the article is about the war between Russia and Ukraine\",\n",
    "    llm_return_type=bool,\n",
    "    distribution=Distribution.BERNOULLI,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Collect all feature definitions\n",
    "feature_definitions = [\n",
    "    mention_of_war,\n",
    "    mention_of_casualties,\n",
    "    mentions_weapons,\n",
    "    mentions_US,\n",
    "    mentions_Russia,\n",
    "    mentions_Ukraine,\n",
    "    mentions_Putin,\n",
    "    russian_ukraine_theme\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model\n",
    "\n",
    "Create a Featuristic classifier using our feature definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "featuristic_classifier = FeaturisticClassifier(\n",
    "    distributions=[d.distribution for d in feature_definitions]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main training and testing function\n",
    "async def train_and_test():\n",
    "    print(\"Extracting features from training data...\")\n",
    "    features_train = await extract_features(\n",
    "        data=data_train,\n",
    "        feature_definitions=feature_definitions\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining classifier...\")\n",
    "    featuristic_classifier.fit(\n",
    "        features=features_train,\n",
    "        Y=y_train\n",
    "    )\n",
    "    \n",
    "    print(\"\\nExtracting features from test data...\")\n",
    "    features_test = await extract_features(\n",
    "        data=data_test,\n",
    "        feature_definitions=feature_definitions\n",
    "    )\n",
    "    \n",
    "    print(\"\\nMaking predictions...\")\n",
    "    predictions = featuristic_classifier.predict(features_test)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training and testing process\n",
    "predictions = await train_and_test()\n",
    "\n",
    "# Calculate and display results\n",
    "correct = np.sum(predictions == y_test)\n",
    "total = len(y_test)\n",
    "accuracy = correct/total\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Correct predictions: {correct}/{total}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
